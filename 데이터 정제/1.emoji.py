import pandas as pd
import re
import emoji 
import html # HTML ì—”í„°í‹° ë””ì½”ë”©ì„ ìœ„í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬
import io

# 1. íŒŒì¼ ë¶ˆëŸ¬ì˜¤ê¸°
file_path = 'gwangju_dessert_cafes_blog_links_bukgu.csv' # ì›ë³¸ íŒŒì¼ì„ ì‚¬ìš©í•˜ì—¬ ì‘ì—…ì„ ë‹¤ì‹œ ì‹œì‘í•©ë‹ˆë‹¤.

try:
    df = pd.read_csv(file_path, encoding='utf-8')
except UnicodeDecodeError:
    # í•œêµ­ì–´ í™˜ê²½ì—ì„œ ì£¼ë¡œ ì‚¬ìš©ë˜ëŠ” cp949 ì¸ì½”ë”©ìœ¼ë¡œ ì¬ì‹œë„
    df = pd.read_csv(file_path, encoding='cp949')
except FileNotFoundError:
    print(f"Error: íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {file_path}")
    exit()

# 2. í…ìŠ¤íŠ¸ ì •ì œ(Cleaning) í•¨ìˆ˜ ì •ì˜ ë° ì ìš© (ì´ëª¨í‹°ì½˜, HTML íƒœê·¸ ë“± ì œê±°)
def clean_text(text):
    """ì´ëª¨í‹°ì½˜, HTML íƒœê·¸ ë° ì—”í„°í‹°ë¥¼ ì•ˆì „í•˜ê²Œ ì œê±°í•˜ëŠ” í•¨ìˆ˜"""
    if pd.isna(text):
        return text
    
    text = str(text)
    
    # 2-1. HTML ì—”í„°í‹° ë””ì½”ë”© (ì˜ˆ: &lt; -> <, &gt; -> >)
    text = html.unescape(text)
    
    # 2-2. HTML íƒœê·¸ ì œê±° (ì˜ˆ: <br>, <a>...</a>)
    text = re.sub('<[^>]*>', '', text)
    
    # 2-3. ì´ëª¨í‹°ì½˜ ì œê±° (emoji ë¼ì´ë¸ŒëŸ¬ë¦¬ ì‚¬ìš©)
    text = emoji.replace_emoji(text, replace='')
    
    # 2-4. ê³¼ë„í•œ ê³µë°±(ì—°ì†ëœ ê³µë°±)ì„ í•˜ë‚˜ì˜ ê³µë°±ìœ¼ë¡œ ì¹˜í™˜í•˜ì—¬ ì •ë¦¬
    text = re.sub('\s+', ' ', text)
    
    return text.strip()

# ì •ì œë¥¼ ì ìš©í•  ì»¬ëŸ¼ ëª©ë¡
text_columns = ['blog_title', 'blog_description', 'content'] 
for col in text_columns:
    if col in df.columns:
        df[col] = df[col].apply(clean_text)


# 3. 'https://blog.naver.com' ê¸°ì¤€ìœ¼ë¡œ ë¦¬ë·°ë¥¼ ë‚˜ëˆ„ê³  ID ë¶€ì—¬
# 'link' ì»¬ëŸ¼ì—ì„œ URLì„ í¬í•¨í•˜ëŠ” í–‰ì„ ìƒˆë¡œìš´ ë¦¬ë·°ì˜ ì‹œì‘ì ìœ¼ë¡œ ê°„ì£¼í•©ë‹ˆë‹¤.
is_new_blog_start = df['link'].astype(str).str.contains('https://blog.naver.com', na=False)
start_indices = df[is_new_blog_start].index.tolist()

individual_reviews = []
for i in range(len(start_indices)):
    start = start_indices[i]
    
    # ë‹¤ìŒ ë¦¬ë·°ì˜ ì‹œì‘ ì¸ë±ìŠ¤ ë˜ëŠ” DataFrameì˜ ëì„ endë¡œ ì„¤ì •
    if i < len(start_indices) - 1:
        end = start_indices[i+1]
    else:
        end = len(df)
    
    # ë¦¬ë·° ë°ì´í„° ì¶”ì¶œ
    review_data = df.iloc[start:end].copy()
    
    # ğŸŒŸ ê° ë¦¬ë·°/ë¸”ë¡œê·¸ í¬ìŠ¤íŠ¸ì— ê³ ìœ  ID í• ë‹¹
    review_data['review_id'] = i + 1 
    
    individual_reviews.append(review_data)

# 4. ë¶„ë¦¬ëœ ëª¨ë“  ë¦¬ë·° ë°ì´í„°ë¥¼ í•˜ë‚˜ì˜ DataFrameìœ¼ë¡œ í•©ì¹©ë‹ˆë‹¤.
if not individual_reviews:
    print("Error: 'https://blog.naver.com'ì„ í¬í•¨í•˜ëŠ” í–‰ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë¦¬ë·°ë¥¼ ë‚˜ëˆŒ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    exit()
    
combined_reviews_df = pd.concat(individual_reviews)

# 5. í•©ì³ì§„ DataFrameì„ ìƒˆë¡œìš´ CSV íŒŒì¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤.
output_file_path = 'naver_blog_reviews_bukgu_combined_final.csv'
combined_reviews_df.to_csv(output_file_path, index=False, encoding='utf-8') 

print(f"âœ… 'https://blog.naver.com' ê¸°ì¤€ìœ¼ë¡œ ì´ {len(individual_reviews)}ê°œì˜ ë¦¬ë·°ê°€ ë¶„ë¦¬ë˜ì–´ í•˜ë‚˜ì˜ íŒŒì¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
print(f"ğŸ“Œ ì €ì¥ëœ íŒŒì¼ ê²½ë¡œ: {output_file_path}")

# 6. ì •ì œ ë° ë¶„ë¦¬ëœ ë°ì´í„°ì˜ êµ¬ì¡°ë¥¼ í™•ì¸í•©ë‹ˆë‹¤.
print("\n--- ì €ì¥ëœ íŒŒì¼ì˜ ìƒìœ„ 5ê°œ í–‰ (review_id í¬í•¨) ---")
pd.set_option('display.max_colwidth', 100) # ë‚´ìš©ì„ ë” ê¸¸ê²Œ í‘œì‹œí•˜ë„ë¡ ì„¤ì •
print(combined_reviews_df[['blog_title', 'content', 'review_id']].head(5))
pd.reset_option('display.max_colwidth')