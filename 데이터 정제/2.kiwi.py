import pandas as pd
from kiwipiepy import Kiwi
import io

# 1. íŒŒì¼ ë¶ˆëŸ¬ì˜¤ê¸°
file_path = 'naver_blog_reviews_bukgu_combined_final.csv' 

try:
    # ì´ì „ì— ë¶„ë¦¬/ì •ì œëœ íŒŒì¼ì„ ì½ì–´ì˜µë‹ˆë‹¤.
    df = pd.read_csv(file_path, encoding='utf-8')
except FileNotFoundError:
    print(f"Error: íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {file_path}")
    exit()

# 2. Kiwi ë¶„ì„ê¸° ì´ˆê¸°í™”
# 'Kiwi()'ë¥¼ í•œ ë²ˆë§Œ ì´ˆê¸°í™”í•˜ì—¬ ë©”ëª¨ë¦¬ì— ì˜¬ë ¤ë†“ê³  ì¬ì‚¬ìš©í•©ë‹ˆë‹¤.
kiwi = Kiwi()

# 3. ë¹ˆë„ ë¶„ì„ì— ì‚¬ìš©í•  í’ˆì‚¬ ì •ì˜
# ì¼ë°˜ì ìœ¼ë¡œ ëª…ì‚¬(NN), ë™ì‚¬(VV), í˜•ìš©ì‚¬(VA)ë¥¼ ì‚¬ìš©í•˜ë©°,
# ì ‘ë¯¸ì‚¬(XSN, XSV, XSA)ë‚˜ ë³´ì¡°ìš©ì–¸(VX) ë“±ì€ ì œì™¸í•˜ê±°ë‚˜ í•„ìš”ì— ë”°ë¼ í¬í•¨í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
# ì—¬ê¸°ì„œëŠ” ì¼ë°˜ì ì¸ ë¹ˆë„ë¶„ì„ì— ìœ ìš©í•œ ëª…ì‚¬, ë™ì‚¬, í˜•ìš©ì‚¬ë§Œ ì¶”ì¶œí•©ë‹ˆë‹¤.
TARGET_POS = ['NNG', 'NNP',  # ì¼ë°˜/ê³ ìœ  ëª…ì‚¬
              'VA',           # í˜•ìš©ì‚¬ (ì˜ˆ: ì¢‹ë‹¤, ì˜ˆì˜ë‹¤)
              'VV']           # ë™ì‚¬ (ì˜ˆ: ë¨¹ë‹¤, ê°€ë‹¤)

# 4. í˜•íƒœì†Œ ë¶„ì„ ë° í† í° ì¶”ì¶œ í•¨ìˆ˜ ì •ì˜
def analyze_and_extract_tokens(text):
    """
    Kiwië¥¼ ì‚¬ìš©í•˜ì—¬ í…ìŠ¤íŠ¸ì—ì„œ ì§€ì •ëœ í’ˆì‚¬(TARGET_POS)ì˜ ì–´ê°„(stem)ë§Œ ì¶”ì¶œí•©ë‹ˆë‹¤.
    """
    if pd.isna(text):
        return []
    
    text = str(text)
    
    # Kiwiì˜ í˜•íƒœì†Œ ë¶„ì„ í•¨ìˆ˜ (tokenize)ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.
    # tokens = kiwi.tokenize(text)
    
    # í…ìŠ¤íŠ¸ë¥¼ êµ¬ë¬¸ ë¶„ì„í•˜ê³ , ë¶„ì„ëœ ê²°ê³¼(morpheme)ì—ì„œ í’ˆì‚¬ë¥¼ í™•ì¸í•˜ì—¬ ì¶”ì¶œí•©ë‹ˆë‹¤.
    results = kiwi.analyze(text)[0][0]
    
    extracted_tokens = []
    for token, pos, _, _ in results:
        # ì¶”ì¶œ ëŒ€ìƒ í’ˆì‚¬ì— í¬í•¨ë˜ê³ , ê¸¸ì´ê°€ 2 ì´ìƒì¸ ë‹¨ì–´ë§Œ ì‚¬ìš© (ë‹¨ìˆœ ì¡°ì‚¬/ì–´ë¯¸ ì œì™¸ ëª©ì )
        # ë™ì‚¬(VV)ë‚˜ í˜•ìš©ì‚¬(VA)ì˜ ê²½ìš° ì–´ê°„(Stem)ì„ ì¶”ì¶œí•˜ì—¬ ì‚¬ìš©í•©ë‹ˆë‹¤. (ì˜ˆ: 'ë¨¹ì—ˆë‹¤' -> 'ë¨¹')
        if pos in TARGET_POS:
            # ë™ì‚¬/í˜•ìš©ì‚¬ëŠ” ì–´ê°„(token)ì„ ì‚¬ìš©í•˜ê³ , ëª…ì‚¬ëŠ” í˜•íƒœì†Œ(token)ë¥¼ ê·¸ëŒ€ë¡œ ì‚¬ìš©
            if len(token) > 1 or pos.startswith('NN'): # ê¸¸ì´ê°€ 2 ì´ìƒ ë˜ëŠ” ëª…ì‚¬ì¸ ê²½ìš°
                extracted_tokens.append(token)
    
    return extracted_tokens

# 5. 'content' ì»¬ëŸ¼ì— í•¨ìˆ˜ ì ìš© ë° ìƒˆ ì»¬ëŸ¼ ìƒì„±
print("ğŸ” 'content' ì»¬ëŸ¼ì— Kiwi í˜•íƒœì†Œ ë¶„ì„ì„ ì ìš© ì¤‘...")
df['kiwi_tokens'] = df['content'].apply(analyze_and_extract_tokens)

# 6. ë¹ˆë„ ë¶„ì„ìš©ìœ¼ë¡œ ì •ë¦¬ëœ ë°ì´í„°ë¥¼ ìƒˆ íŒŒì¼ë¡œ ì €ì¥
output_file_path = 'bukgu_kiwi_frequency_analysis_ready.csv'
df.to_csv(output_file_path, index=False, encoding='utf-8')

print("\n---------------------------------------------------------")
print(f"âœ… ë¹ˆë„ ë¶„ì„ìš© ë°ì´í„° ì¤€ë¹„ ì™„ë£Œ.")
print(f"ğŸ“Œ ì €ì¥ëœ íŒŒì¼ ê²½ë¡œ: {output_file_path}")
print("---------------------------------------------------------")

# 7. ê²°ê³¼ í™•ì¸ (ì¶”ì¶œëœ í† í° ëª©ë¡ í™•ì¸)
print("\n--- ì¶”ì¶œëœ í† í° í™•ì¸ (ìƒìœ„ 3ê°œ ë¦¬ë·°) ---")
for i, row in df.head(3).iterrows():
    print(f"ë¦¬ë·° ID {row['review_id']}: {row['kiwi_tokens'][:10]}... ({len(row['kiwi_tokens'])}ê°œ í† í°)")